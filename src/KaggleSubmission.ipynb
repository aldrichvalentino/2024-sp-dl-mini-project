{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet for CIFAR-10\n",
    "\n",
    "We take the inspiration for this code from the github link `pytorch-cifar`. It provides the basic block implementation of a Residual Network architecture. In our project, we declare a ResNet12 architecture, with four layers and `[2, 1, 1, 1]` blocks in each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, dropout_rate=0.25):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.dropout = nn.Dropout(dropout_rate)  # Add dropout\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.dropout(out)  # Apply dropout after first activation\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10, dropout_rate=0.5):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1, dropout_rate=dropout_rate)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2, dropout_rate=dropout_rate)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2, dropout_rate=dropout_rate)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2, dropout_rate=dropout_rate)\n",
    "        self.dropout = nn.Dropout(dropout_rate)  # Add dropout before the final layer\n",
    "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride, dropout_rate):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride, dropout_rate))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.dropout(out)  # Apply dropout before the final fully connected layer\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "def ResNet12():\n",
    "    return ResNet(BasicBlock, [2, 1, 1, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a few helper functions to import data and format training progress. Some are also taken from the `python-cifar` utility functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import zipfile\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "\n",
    "term_width = 50\n",
    "last_time = time.time()\n",
    "begin_time = last_time\n",
    "\n",
    "def progress_bar(current, total, msg=None):\n",
    "    bar_length = 60\n",
    "    progress = current / total\n",
    "\n",
    "    block = int(round(bar_length * progress))\n",
    "    # Use '>' as an arrow to indicate current progress position\n",
    "    # Note: The arrow is positioned at the end of the filled portion, except when progress is 0\n",
    "    arrow = \">\" if block < bar_length else \"\"\n",
    "    text = \"\\rProgress: [{0}{1}{2}] {3:.2f}% ({4}/{5}) {6}\".format(\n",
    "        \"=\" * (block - 1 if block > 0 else 0), arrow,\n",
    "        \"-\" * (bar_length - block), progress * 100, current, total,\n",
    "        msg if msg else \"\")\n",
    "    sys.stdout.write(text)\n",
    "    sys.stdout.flush()\n",
    "    if current == total:\n",
    "        sys.stdout.write('\\n')\n",
    "\n",
    "def format_time(seconds):\n",
    "    days = int(seconds / 3600/24)\n",
    "    seconds = seconds - days*3600*24\n",
    "    hours = int(seconds / 3600)\n",
    "    seconds = seconds - hours*3600\n",
    "    minutes = int(seconds / 60)\n",
    "    seconds = seconds - minutes*60\n",
    "    secondsf = int(seconds)\n",
    "    seconds = seconds - secondsf\n",
    "    millis = int(seconds*1000)\n",
    "\n",
    "    f = ''\n",
    "    i = 1\n",
    "    if days > 0:\n",
    "        f += str(days) + 'D'\n",
    "        i += 1\n",
    "    if hours > 0 and i <= 2:\n",
    "        f += str(hours) + 'h'\n",
    "        i += 1\n",
    "    if minutes > 0 and i <= 2:\n",
    "        f += str(minutes) + 'm'\n",
    "        i += 1\n",
    "    if secondsf > 0 and i <= 2:\n",
    "        f += str(secondsf) + 's'\n",
    "        i += 1\n",
    "    if millis > 0 and i <= 2:\n",
    "        f += str(millis) + 'ms'\n",
    "        i += 1\n",
    "    if f == '':\n",
    "        f = '0ms'\n",
    "    return f\n",
    "\n",
    "\n",
    "def unpickle(filename):\n",
    "    zf = zipfile.ZipFile(filename, \"r\")\n",
    "    data = pickle.loads(zf.open(\"cifar_test_nolabels.pkl\").read())\n",
    "    zf.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we instanciate our model and count the number of parameters. We also import the CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "50000 110000\n",
      "==> Building model..\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "Count params:  4977226\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "from PIL import Image\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "class CIFARLikeDataset(Dataset):\n",
    "    def __init__(self, folder_path, transform=None):\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "\n",
    "        # Load all batch files\n",
    "        for i in range(1, 6):\n",
    "            file_path = os.path.join(folder_path, f'data_batch_{i}')\n",
    "            with open(file_path, 'rb') as file:\n",
    "                batch = pickle.load(file, encoding='bytes')\n",
    "                self.data.append(batch[b'data'])\n",
    "                self.labels.extend(batch[b'labels'])\n",
    "\n",
    "        self.data = np.vstack(self.data).reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # reshape and transpose to HWC format\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Convert numpy array to PIL Image\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "    \n",
    "custom_data_path = './data'  # Update this path\n",
    "cifar_like_train = CIFARLikeDataset(folder_path=custom_data_path, transform=transform_train)\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "combined_set = torch.utils.data.ConcatDataset([trainset, testset, cifar_like_train])\n",
    "print(len(trainset), len(combined_set))\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    combined_set, batch_size=128, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Model\n",
    "print('==> Building model..')\n",
    "net = ResNet12()\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(net)\n",
    "count_params = count_parameters(net)\n",
    "print(\"Count params: \", count_params)\n",
    "assert count_params < 5000000, \"Parameters must be lower than 5 million\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "For training, we use `CrossEntropyLoss` to meausre how the model is doing. This is a suitable loss for an image classification task. Next, we use the `Adam` optimizer to train the parameters. The learning rate will be updated using cosine annealing schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "# Loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Training Optimizer\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "# History\n",
    "train_loss_hist = []\n",
    "test_loss_hist = []\n",
    "\n",
    "# Training\n",
    "def train(epoch, dataloader):\n",
    "    global best_acc\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        progress_bar(batch_idx+1, len(dataloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                     % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "    \n",
    "    # save the history\n",
    "    train_loss_hist.append(train_loss)\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc >= best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/ckpt.pth')\n",
    "        best_acc = acc\n",
    "\n",
    "\n",
    "def test(epoch, dataloader):\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "            progress_bar(batch_idx+1, len(dataloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                          % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    # save the history\n",
    "    test_loss_hist.append(test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do 25 epochs of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 1.315 | Acc: 51.830% (57013/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 1.122 | Acc: 60.120% (6012/10000)\n",
      "\n",
      "Epoch: 1\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.919 | Acc: 66.989% (73688/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.818 | Acc: 70.420% (7042/10000)\n",
      "\n",
      "Epoch: 2\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.783 | Acc: 72.011% (79212/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.655 | Acc: 76.240% (7624/10000)\n",
      "\n",
      "Epoch: 3\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.698 | Acc: 75.170% (82687/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.560 | Acc: 79.730% (7973/10000)\n",
      "\n",
      "Epoch: 4\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.627 | Acc: 77.785% (85564/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.453 | Acc: 84.220% (8422/10000)\n",
      "\n",
      "Epoch: 5\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.570 | Acc: 79.912% (87903/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.404 | Acc: 85.820% (8582/10000)\n",
      "\n",
      "Epoch: 6\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.522 | Acc: 81.517% (89669/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.351 | Acc: 87.880% (8788/10000)\n",
      "\n",
      "Epoch: 7\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.481 | Acc: 83.109% (91420/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.319 | Acc: 88.950% (8895/10000)\n",
      "\n",
      "Epoch: 8\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.450 | Acc: 84.126% (92539/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.274 | Acc: 90.470% (9047/10000)\n",
      "\n",
      "Epoch: 9\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.419 | Acc: 85.188% (93707/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.261 | Acc: 90.780% (9078/10000)\n",
      "\n",
      "Epoch: 10\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.396 | Acc: 86.125% (94737/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.225 | Acc: 92.150% (9215/10000)\n",
      "\n",
      "Epoch: 11\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.371 | Acc: 86.922% (95614/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.201 | Acc: 93.330% (9333/10000)\n",
      "\n",
      "Epoch: 12\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.356 | Acc: 87.446% (96191/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.185 | Acc: 93.490% (9349/10000)\n",
      "\n",
      "Epoch: 13\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.339 | Acc: 87.984% (96782/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.161 | Acc: 94.550% (9455/10000)\n",
      "\n",
      "Epoch: 14\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.320 | Acc: 88.728% (97601/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.133 | Acc: 95.940% (9594/10000)\n",
      "\n",
      "Epoch: 15\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.303 | Acc: 89.181% (98099/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.127 | Acc: 95.850% (9585/10000)\n",
      "\n",
      "Epoch: 16\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.293 | Acc: 89.561% (98517/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.113 | Acc: 96.750% (9675/10000)\n",
      "\n",
      "Epoch: 17\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.280 | Acc: 90.079% (99087/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.102 | Acc: 96.810% (9681/10000)\n",
      "\n",
      "Epoch: 18\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.266 | Acc: 90.478% (99526/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.099 | Acc: 97.100% (9710/10000)\n",
      "\n",
      "Epoch: 19\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.260 | Acc: 90.705% (99775/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.078 | Acc: 97.920% (9792/10000)\n",
      "\n",
      "Epoch: 20\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.248 | Acc: 91.143% (100257/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.073 | Acc: 98.270% (9827/10000)\n",
      "\n",
      "Epoch: 21\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.239 | Acc: 91.474% (100621/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.069 | Acc: 98.140% (9814/10000)\n",
      "\n",
      "Epoch: 22\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.230 | Acc: 91.716% (100888/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.067 | Acc: 98.380% (9838/10000)\n",
      "\n",
      "Epoch: 23\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.226 | Acc: 91.918% (101110/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.055 | Acc: 98.810% (9881/10000)\n",
      "\n",
      "Epoch: 24\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.216 | Acc: 92.278% (101506/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.055 | Acc: 98.690% (9869/10000)\n",
      "\n",
      "Epoch: 25\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.205 | Acc: 92.648% (101913/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.051 | Acc: 98.780% (9878/10000)\n",
      "\n",
      "Epoch: 26\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.203 | Acc: 92.779% (102057/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.048 | Acc: 98.870% (9887/10000)\n",
      "\n",
      "Epoch: 27\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.197 | Acc: 92.961% (102257/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.040 | Acc: 99.230% (9923/10000)\n",
      "\n",
      "Epoch: 28\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.191 | Acc: 93.125% (102437/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.039 | Acc: 99.300% (9930/10000)\n",
      "\n",
      "Epoch: 29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.186 | Acc: 93.325% (102658/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.034 | Acc: 99.410% (9941/10000)\n",
      "\n",
      "Epoch: 30\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.180 | Acc: 93.537% (102891/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.031 | Acc: 99.460% (9946/10000)\n",
      "\n",
      "Epoch: 31\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.176 | Acc: 93.706% (103077/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.031 | Acc: 99.590% (9959/10000)\n",
      "\n",
      "Epoch: 32\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.172 | Acc: 93.842% (103226/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.028 | Acc: 99.520% (9952/10000)\n",
      "\n",
      "Epoch: 33\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.166 | Acc: 94.060% (103466/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.028 | Acc: 99.500% (9950/10000)\n",
      "\n",
      "Epoch: 34\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.165 | Acc: 94.077% (103485/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.027 | Acc: 99.650% (9965/10000)\n",
      "\n",
      "Epoch: 35\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.158 | Acc: 94.291% (103720/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.025 | Acc: 99.730% (9973/10000)\n",
      "\n",
      "Epoch: 36\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.151 | Acc: 94.539% (103993/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.023 | Acc: 99.740% (9974/10000)\n",
      "\n",
      "Epoch: 37\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.153 | Acc: 94.559% (104015/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.021 | Acc: 99.710% (9971/10000)\n",
      "\n",
      "Epoch: 38\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.147 | Acc: 94.754% (104229/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.022 | Acc: 99.730% (9973/10000)\n",
      "\n",
      "Epoch: 39\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.143 | Acc: 94.917% (104409/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.017 | Acc: 99.870% (9987/10000)\n",
      "\n",
      "Epoch: 40\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.140 | Acc: 95.003% (104503/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.017 | Acc: 99.810% (9981/10000)\n",
      "\n",
      "Epoch: 41\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.135 | Acc: 95.114% (104625/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.016 | Acc: 99.830% (9983/10000)\n",
      "\n",
      "Epoch: 42\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.135 | Acc: 95.169% (104686/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.017 | Acc: 99.880% (9988/10000)\n",
      "\n",
      "Epoch: 43\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.133 | Acc: 95.232% (104755/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.016 | Acc: 99.920% (9992/10000)\n",
      "\n",
      "Epoch: 44\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.128 | Acc: 95.435% (104978/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.013 | Acc: 99.870% (9987/10000)\n",
      "\n",
      "Epoch: 45\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.128 | Acc: 95.405% (104945/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.014 | Acc: 99.880% (9988/10000)\n",
      "\n",
      "Epoch: 46\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.122 | Acc: 95.595% (105155/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.012 | Acc: 99.940% (9994/10000)\n",
      "\n",
      "Epoch: 47\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.123 | Acc: 95.555% (105111/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.016 | Acc: 99.780% (9978/10000)\n",
      "\n",
      "Epoch: 48\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.118 | Acc: 95.805% (105385/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.014 | Acc: 99.850% (9985/10000)\n",
      "\n",
      "Epoch: 49\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.118 | Acc: 95.828% (105411/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.011 | Acc: 99.960% (9996/10000)\n",
      "\n",
      "Epoch: 50\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.114 | Acc: 95.983% (105581/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.010 | Acc: 99.950% (9995/10000)\n",
      "\n",
      "Epoch: 51\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.113 | Acc: 95.945% (105540/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.010 | Acc: 99.890% (9989/10000)\n",
      "\n",
      "Epoch: 52\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.108 | Acc: 96.168% (105785/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.009 | Acc: 99.910% (9991/10000)\n",
      "\n",
      "Epoch: 53\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.108 | Acc: 96.155% (105770/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.007 | Acc: 99.970% (9997/10000)\n",
      "\n",
      "Epoch: 54\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.105 | Acc: 96.245% (105870/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.009 | Acc: 99.920% (9992/10000)\n",
      "\n",
      "Epoch: 55\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.102 | Acc: 96.332% (105965/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.008 | Acc: 99.960% (9996/10000)\n",
      "\n",
      "Epoch: 56\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.102 | Acc: 96.403% (106043/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.008 | Acc: 99.950% (9995/10000)\n",
      "\n",
      "Epoch: 57\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.100 | Acc: 96.415% (106056/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.007 | Acc: 99.970% (9997/10000)\n",
      "\n",
      "Epoch: 58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.097 | Acc: 96.549% (106204/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.007 | Acc: 99.950% (9995/10000)\n",
      "\n",
      "Epoch: 59\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.096 | Acc: 96.630% (106293/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.007 | Acc: 99.940% (9994/10000)\n",
      "\n",
      "Epoch: 60\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.094 | Acc: 96.616% (106278/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.006 | Acc: 99.930% (9993/10000)\n",
      "\n",
      "Epoch: 61\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.095 | Acc: 96.579% (106237/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.007 | Acc: 99.940% (9994/10000)\n",
      "\n",
      "Epoch: 62\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.091 | Acc: 96.788% (106467/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.005 | Acc: 99.990% (9999/10000)\n",
      "\n",
      "Epoch: 63\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.090 | Acc: 96.790% (106469/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.006 | Acc: 99.970% (9997/10000)\n",
      "\n",
      "Epoch: 64\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.090 | Acc: 96.821% (106503/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.005 | Acc: 99.980% (9998/10000)\n",
      "\n",
      "Epoch: 65\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.088 | Acc: 96.898% (106588/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.006 | Acc: 99.960% (9996/10000)\n",
      "\n",
      "Epoch: 66\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.085 | Acc: 96.955% (106651/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.005 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 67\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.083 | Acc: 97.052% (106757/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.004 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 68\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.081 | Acc: 97.177% (106895/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.005 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 69\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.081 | Acc: 97.151% (106866/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.004 | Acc: 99.980% (9998/10000)\n",
      "\n",
      "Epoch: 70\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.079 | Acc: 97.243% (106967/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.003 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 71\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.080 | Acc: 97.172% (106889/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.003 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 72\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.076 | Acc: 97.284% (107012/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.003 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 73\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.077 | Acc: 97.302% (107032/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.004 | Acc: 99.980% (9998/10000)\n",
      "\n",
      "Epoch: 74\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.074 | Acc: 97.356% (107092/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.002 | Acc: 99.990% (9999/10000)\n",
      "\n",
      "Epoch: 75\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.075 | Acc: 97.356% (107092/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.003 | Acc: 99.990% (9999/10000)\n",
      "\n",
      "Epoch: 76\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.070 | Acc: 97.484% (107232/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.003 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 77\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.070 | Acc: 97.549% (107304/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.003 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 78\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.070 | Acc: 97.538% (107292/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.003 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 79\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.069 | Acc: 97.514% (107265/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.003 | Acc: 99.980% (9998/10000)\n",
      "\n",
      "Epoch: 80\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.066 | Acc: 97.654% (107419/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.002 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 81\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.066 | Acc: 97.686% (107455/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.002 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 82\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.066 | Acc: 97.634% (107397/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.002 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 83\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.065 | Acc: 97.672% (107439/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.002 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 84\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.063 | Acc: 97.794% (107573/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.002 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 85\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.063 | Acc: 97.750% (107525/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.002 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 86\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.060 | Acc: 97.884% (107672/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.002 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.060 | Acc: 97.873% (107660/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.002 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 88\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.058 | Acc: 97.956% (107752/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.002 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 89\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.058 | Acc: 97.941% (107735/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 90\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.058 | Acc: 97.974% (107771/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.002 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 91\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.057 | Acc: 98.003% (107803/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 92\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.056 | Acc: 98.052% (107857/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 93\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.054 | Acc: 98.133% (107946/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 99.990% (9999/10000)\n",
      "\n",
      "Epoch: 94\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.053 | Acc: 98.099% (107909/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 95\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.053 | Acc: 98.162% (107978/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 96\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.052 | Acc: 98.208% (108029/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 97\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.052 | Acc: 98.190% (108009/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 98\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.050 | Acc: 98.232% (108055/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 99\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.051 | Acc: 98.194% (108013/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 100\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.051 | Acc: 98.221% (108043/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 101\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.047 | Acc: 98.350% (108185/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 102\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.048 | Acc: 98.339% (108173/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 103\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.048 | Acc: 98.307% (108138/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 104\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.046 | Acc: 98.368% (108205/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 105\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.044 | Acc: 98.489% (108338/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 106\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.046 | Acc: 98.401% (108241/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 107\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.044 | Acc: 98.476% (108324/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 108\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.043 | Acc: 98.440% (108284/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 109\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.042 | Acc: 98.509% (108360/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 110\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.041 | Acc: 98.551% (108406/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 111\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.041 | Acc: 98.541% (108395/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 112\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.041 | Acc: 98.547% (108402/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 113\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.039 | Acc: 98.614% (108475/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 114\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.039 | Acc: 98.655% (108520/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 115\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.039 | Acc: 98.649% (108514/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.038 | Acc: 98.666% (108533/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 117\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.038 | Acc: 98.669% (108536/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 118\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.037 | Acc: 98.690% (108559/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 119\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.034 | Acc: 98.807% (108688/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 120\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.035 | Acc: 98.845% (108730/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 121\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.035 | Acc: 98.818% (108700/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 122\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.034 | Acc: 98.826% (108709/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 123\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.034 | Acc: 98.794% (108673/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 124\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.035 | Acc: 98.828% (108711/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 125\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.032 | Acc: 98.919% (108811/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 126\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.034 | Acc: 98.819% (108701/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 127\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.033 | Acc: 98.869% (108756/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 128\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.029 | Acc: 99.009% (108910/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 129\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.031 | Acc: 98.919% (108811/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 130\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.030 | Acc: 98.975% (108873/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 131\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.029 | Acc: 99.012% (108913/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 132\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.030 | Acc: 98.980% (108878/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 133\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.028 | Acc: 99.015% (108917/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 134\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.029 | Acc: 98.959% (108855/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 135\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.028 | Acc: 98.999% (108899/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 136\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.028 | Acc: 99.005% (108905/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 137\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.028 | Acc: 99.066% (108973/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 138\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.027 | Acc: 99.094% (109003/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 139\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.025 | Acc: 99.113% (109024/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 140\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.027 | Acc: 99.053% (108958/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 141\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.025 | Acc: 99.165% (109081/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 142\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.025 | Acc: 99.173% (109090/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 143\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.025 | Acc: 99.147% (109062/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 144\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.024 | Acc: 99.171% (109088/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.024 | Acc: 99.186% (109105/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 146\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.023 | Acc: 99.210% (109131/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 147\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.023 | Acc: 99.170% (109087/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 148\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.023 | Acc: 99.205% (109126/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 149\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.023 | Acc: 99.199% (109119/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 150\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.022 | Acc: 99.269% (109196/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 151\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.022 | Acc: 99.262% (109188/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 152\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.022 | Acc: 99.266% (109193/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 153\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.021 | Acc: 99.302% (109232/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 154\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.021 | Acc: 99.277% (109205/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 155\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.022 | Acc: 99.251% (109176/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 156\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.021 | Acc: 99.254% (109179/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 157\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.020 | Acc: 99.315% (109247/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 158\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.021 | Acc: 99.294% (109223/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 159\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.020 | Acc: 99.304% (109234/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 160\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.021 | Acc: 99.325% (109258/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 161\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.020 | Acc: 99.314% (109245/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 162\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.019 | Acc: 99.336% (109270/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 163\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.020 | Acc: 99.328% (109261/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 164\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.019 | Acc: 99.378% (109316/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 165\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.020 | Acc: 99.335% (109268/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 166\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.018 | Acc: 99.381% (109319/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 167\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.018 | Acc: 99.385% (109324/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 168\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.019 | Acc: 99.341% (109275/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 169\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.017 | Acc: 99.415% (109357/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 170\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.019 | Acc: 99.365% (109301/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 171\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.018 | Acc: 99.370% (109307/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 172\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.017 | Acc: 99.397% (109337/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 173\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.018 | Acc: 99.373% (109310/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.018 | Acc: 99.376% (109314/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 175\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.017 | Acc: 99.433% (109376/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 176\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.018 | Acc: 99.375% (109312/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 177\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.017 | Acc: 99.435% (109378/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 178\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.017 | Acc: 99.428% (109371/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 179\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.018 | Acc: 99.395% (109334/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 180\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.016 | Acc: 99.464% (109410/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 181\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.017 | Acc: 99.436% (109380/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 182\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.016 | Acc: 99.450% (109395/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 183\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.016 | Acc: 99.435% (109379/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 184\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.018 | Acc: 99.390% (109329/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 185\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.017 | Acc: 99.432% (109375/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 186\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.017 | Acc: 99.435% (109378/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 187\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.016 | Acc: 99.430% (109373/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 188\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.016 | Acc: 99.460% (109406/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 189\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.016 | Acc: 99.454% (109399/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 190\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.016 | Acc: 99.450% (109395/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 191\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.016 | Acc: 99.447% (109392/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 192\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.016 | Acc: 99.468% (109415/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 193\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.016 | Acc: 99.429% (109372/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 194\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.016 | Acc: 99.437% (109381/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 195\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.016 | Acc: 99.436% (109380/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 196\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.017 | Acc: 99.439% (109383/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 197\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.016 | Acc: 99.458% (109404/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 198\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.016 | Acc: 99.453% (109398/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 199\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.016 | Acc: 99.419% (109361/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 200\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.016 | Acc: 99.459% (109405/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 201\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.016 | Acc: 99.463% (109409/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 202\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.016 | Acc: 99.460% (109406/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.017 | Acc: 99.411% (109352/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 204\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.017 | Acc: 99.445% (109389/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 205\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.016 | Acc: 99.485% (109433/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 206\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.016 | Acc: 99.419% (109361/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 207\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.016 | Acc: 99.457% (109403/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 208\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.015 | Acc: 99.477% (109425/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 209\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.017 | Acc: 99.431% (109374/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 210\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.016 | Acc: 99.458% (109404/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 211\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.017 | Acc: 99.435% (109379/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 212\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.017 | Acc: 99.415% (109357/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 213\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.017 | Acc: 99.426% (109369/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 214\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.016 | Acc: 99.475% (109422/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 215\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.017 | Acc: 99.454% (109399/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 216\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.016 | Acc: 99.452% (109397/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 217\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.016 | Acc: 99.435% (109378/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 218\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.017 | Acc: 99.446% (109391/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 219\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.015 | Acc: 99.473% (109420/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 220\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.017 | Acc: 99.415% (109356/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 221\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.016 | Acc: 99.434% (109377/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 222\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.017 | Acc: 99.458% (109404/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 223\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.015 | Acc: 99.490% (109439/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 224\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.015 | Acc: 99.475% (109422/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 225\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.015 | Acc: 99.496% (109446/110000)\n",
      "Saving..\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 226\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.015 | Acc: 99.478% (109426/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 227\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.017 | Acc: 99.442% (109386/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 228\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.016 | Acc: 99.453% (109398/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 229\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.016 | Acc: 99.479% (109427/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 230\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.016 | Acc: 99.460% (109406/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 231\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.016 | Acc: 99.444% (109388/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 232\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.016 | Acc: 99.462% (109408/110000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 233\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.016 | Acc: 99.440% (109384/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 234\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.017 | Acc: 99.423% (109365/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 235\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.017 | Acc: 99.411% (109352/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 236\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.016 | Acc: 99.435% (109378/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 237\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.017 | Acc: 99.430% (109373/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 238\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.016 | Acc: 99.447% (109392/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 239\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.016 | Acc: 99.481% (109429/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 240\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.017 | Acc: 99.434% (109377/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 241\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.017 | Acc: 99.421% (109363/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 242\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.017 | Acc: 99.397% (109337/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 243\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.017 | Acc: 99.441% (109385/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 244\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.018 | Acc: 99.385% (109323/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 245\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.018 | Acc: 99.383% (109321/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 246\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.019 | Acc: 99.339% (109273/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 247\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.017 | Acc: 99.423% (109365/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 248\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.018 | Acc: 99.355% (109290/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 249\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.017 | Acc: 99.404% (109344/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 250\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.018 | Acc: 99.374% (109311/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 251\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.018 | Acc: 99.390% (109329/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 252\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.019 | Acc: 99.326% (109259/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 253\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.018 | Acc: 99.391% (109330/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 254\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.017 | Acc: 99.415% (109357/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 255\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.019 | Acc: 99.338% (109272/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 256\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.018 | Acc: 99.343% (109277/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 257\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.020 | Acc: 99.326% (109259/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 258\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.018 | Acc: 99.385% (109324/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 259\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.019 | Acc: 99.310% (109241/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 260\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.019 | Acc: 99.343% (109277/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 261\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.019 | Acc: 99.342% (109276/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.021 | Acc: 99.274% (109201/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 263\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.020 | Acc: 99.288% (109217/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 264\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.020 | Acc: 99.302% (109232/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 265\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.021 | Acc: 99.280% (109208/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 266\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.022 | Acc: 99.272% (109199/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 267\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.021 | Acc: 99.275% (109203/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 268\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.021 | Acc: 99.298% (109228/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 269\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.021 | Acc: 99.284% (109212/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 270\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.022 | Acc: 99.258% (109184/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 271\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.023 | Acc: 99.204% (109124/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 272\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.023 | Acc: 99.207% (109128/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 273\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.022 | Acc: 99.214% (109135/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 274\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.023 | Acc: 99.227% (109150/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 275\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.023 | Acc: 99.222% (109144/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 276\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.022 | Acc: 99.211% (109132/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 277\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.024 | Acc: 99.185% (109103/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 278\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.024 | Acc: 99.188% (109107/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 279\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.024 | Acc: 99.185% (109103/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 280\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.025 | Acc: 99.138% (109052/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 281\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.025 | Acc: 99.173% (109090/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 282\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.025 | Acc: 99.149% (109064/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 283\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.026 | Acc: 99.133% (109046/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 284\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.026 | Acc: 99.117% (109029/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 285\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.027 | Acc: 99.058% (108964/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 286\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.025 | Acc: 99.128% (109041/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 287\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.027 | Acc: 99.066% (108973/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 288\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.027 | Acc: 99.080% (108988/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 289\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.026 | Acc: 99.095% (109004/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 290\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.030 | Acc: 98.960% (108856/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 291\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.031 | Acc: 98.935% (108828/110000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 292\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.030 | Acc: 98.963% (108859/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 293\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.029 | Acc: 99.008% (108909/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 294\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.030 | Acc: 98.975% (108873/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 295\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.031 | Acc: 98.963% (108859/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 296\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.029 | Acc: 98.984% (108882/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 297\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.031 | Acc: 98.940% (108834/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 298\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.031 | Acc: 98.964% (108860/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 299\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.030 | Acc: 98.912% (108803/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 300\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.032 | Acc: 98.914% (108805/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 301\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.032 | Acc: 98.905% (108795/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 302\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.032 | Acc: 98.885% (108774/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 303\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.033 | Acc: 98.844% (108728/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 304\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.035 | Acc: 98.804% (108684/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 305\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.034 | Acc: 98.878% (108766/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 306\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.034 | Acc: 98.803% (108683/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 99.990% (9999/10000)\n",
      "\n",
      "Epoch: 307\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.036 | Acc: 98.726% (108599/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 308\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.035 | Acc: 98.813% (108694/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 309\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.035 | Acc: 98.807% (108688/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 310\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.035 | Acc: 98.782% (108660/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 311\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.034 | Acc: 98.833% (108716/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 312\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.036 | Acc: 98.761% (108637/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 99.990% (9999/10000)\n",
      "\n",
      "Epoch: 313\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.036 | Acc: 98.768% (108645/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 314\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.036 | Acc: 98.728% (108601/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 315\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.039 | Acc: 98.644% (108508/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 316\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.038 | Acc: 98.754% (108629/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 99.990% (9999/10000)\n",
      "\n",
      "Epoch: 317\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.039 | Acc: 98.662% (108528/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 318\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.039 | Acc: 98.655% (108521/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 319\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.039 | Acc: 98.669% (108536/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 320\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.037 | Acc: 98.715% (108587/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 99.990% (9999/10000)\n",
      "\n",
      "Epoch: 321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.041 | Acc: 98.585% (108444/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 322\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.040 | Acc: 98.604% (108464/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 323\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.040 | Acc: 98.629% (108492/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 324\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.040 | Acc: 98.599% (108459/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 325\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.040 | Acc: 98.625% (108487/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 326\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.040 | Acc: 98.615% (108476/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 99.990% (9999/10000)\n",
      "\n",
      "Epoch: 327\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.041 | Acc: 98.565% (108422/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 328\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.042 | Acc: 98.583% (108441/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 329\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.042 | Acc: 98.543% (108397/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 330\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.043 | Acc: 98.525% (108378/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 331\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.042 | Acc: 98.540% (108394/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 99.990% (9999/10000)\n",
      "\n",
      "Epoch: 332\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.042 | Acc: 98.542% (108396/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 333\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.043 | Acc: 98.520% (108372/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 334\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.043 | Acc: 98.495% (108344/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 335\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.043 | Acc: 98.528% (108381/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 336\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.046 | Acc: 98.382% (108220/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 337\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.043 | Acc: 98.490% (108339/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 338\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.045 | Acc: 98.458% (108304/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 339\n",
      "Progress: [===========================================================] 100.00% (860/860) Loss: 0.044 | Acc: 98.491% (108340/110000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 340\n",
      "Progress: [=====================================================>------] 90.12% (775/860) Loss: 0.045 | Acc: 98.445% (97657/99200)"
     ]
    }
   ],
   "source": [
    "# Do 25 epoch\n",
    "for epoch in range(start_epoch, start_epoch+500):\n",
    "    train(epoch, trainloader)\n",
    "    test(epoch, testloader)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe the loss over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(train_loss_hist, '-', linewidth=3, label='Train Error')\n",
    "plt.plot(test_loss_hist, '-', linewidth=3, label='Test Error')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also can see the prediction performance on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (input_test,label_test) in enumerate(testloader):\n",
    "        input_test = input_test.to(device)\n",
    "        outputs = net(input_test.float())\n",
    "        _, predicted = outputs.max(1)\n",
    "        labels.append(predicted)\n",
    "\n",
    "# flatten the labels\n",
    "pred = np.array([])\n",
    "for batch in labels:\n",
    "    pred = np.append(pred, batch.tolist())\n",
    "\n",
    "# predict performance\n",
    "cf_matrix = confusion_matrix(testset.targets, pred)\n",
    "cf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like all labels have around 90% accuracy score. We see that label 2 ('bird') has the lowest accuracy of 88.7%. Let's look at some wrong prediction examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print_testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 10))\n",
    "count = 0\n",
    "\n",
    "for i in range(0, len(pred)):\n",
    "    if print_testset.targets[i] != pred[i]:\n",
    "        # print the image\n",
    "        im = print_testset[i][0]\n",
    "        ax[count].imshow(im)\n",
    "        ax[count].set_title(\"Act:%s Pred:%s\" % (classes[print_testset.targets[i]], classes[int(pred[i])]))\n",
    "        count += 1\n",
    "\n",
    "    if count == 3:\n",
    "        break\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our best result, we trained the model using the combined dataset for 100 epochs with the RTX8000 GPU is NYU's HPC cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do 100 epoch\n",
    "for epoch in range(start_epoch, start_epoch+100):\n",
    "    train(epoch, trainloader)\n",
    "    test(epoch, testloader)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "For Kaggle's data prediction, we will import the trained model and start predicting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.init as init\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Model\n",
    "print('==> Building model..')\n",
    "net = ResNet12()\n",
    "net = net.to(device)\n",
    "net = torch.nn.DataParallel(net)\n",
    "if device == 'cuda':\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "# load state\n",
    "saved_model = torch.load('./checkpoint/ckpt.pth', map_location=torch.device(device))\n",
    "net.load_state_dict(saved_model['net'])\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the raw data and predict in batches of a thousand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "cifar_test_nolabels = unpickle(\"../data/cifar_test_nolabels.pkl.zip\")\n",
    "competition_data = cifar_test_nolabels[b'data']\n",
    "y_id = cifar_test_nolabels[b'ids']\n",
    "\n",
    "competitionset = []\n",
    "for d in competition_data:\n",
    "    # transpose flatten CIFAR image to RGB\n",
    "    d = d.reshape(3, 32, 32).transpose(1,2,0)\n",
    "    im = Image.fromarray(d, mode='RGB')\n",
    "    im = transform_test(im)\n",
    "    competitionset.append(im)\n",
    "\n",
    "competitionloader = torch.utils.data.DataLoader(\n",
    "    competitionset, batch_size=1000, shuffle=False)\n",
    "\n",
    "labels = []\n",
    "\n",
    "def competition_test():\n",
    "    net.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, input_test in enumerate(competitionloader):\n",
    "            input_test = input_test.to(device)\n",
    "            outputs = net(input_test.float())\n",
    "            _, predicted = outputs.max(1)\n",
    "            labels.append(predicted)\n",
    "            print(\"Batch %d done\" % (batch_idx + 1))\n",
    "\n",
    "            \n",
    "competition_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we write the prediction labels into a .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# flatten the labels\n",
    "pred = np.array([])\n",
    "for batch in labels:\n",
    "    pred = np.append(pred, batch.tolist())\n",
    "\n",
    "\n",
    "competition_data_ids = unpickle(\"../data/cifar_test_nolabels.pkl.zip\")[b'ids']\n",
    "    \n",
    "# create dataframe to save prediction\n",
    "df = pd.DataFrame()\n",
    "df['ID'] = competition_data_ids\n",
    "df['Label'] = pred\n",
    "df['Label'] = df['Label'].astype(int)\n",
    "\n",
    "df.to_csv('out.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
