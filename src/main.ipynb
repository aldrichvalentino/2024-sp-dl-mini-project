{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet for CIFAR-10\n",
    "\n",
    "We take the inspiration for this code from the github repository `pytorch-cifar`. It provides the basic block implementation of a Residual Network architecture. In our project, we declare a ResNet12 architecture, with four layers and `[2, 1, 1, 1]` blocks in each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, dropout_rate=0.25):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.dropout = nn.Dropout(dropout_rate)  # Add dropout\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.dropout(out)  # Apply dropout after first activation\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10, dropout_rate=0.5):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1, dropout_rate=dropout_rate)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2, dropout_rate=dropout_rate)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2, dropout_rate=dropout_rate)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2, dropout_rate=dropout_rate)\n",
    "        self.dropout = nn.Dropout(dropout_rate)  # Add dropout before the final layer\n",
    "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride, dropout_rate):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride, dropout_rate))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.dropout(out)  # Apply dropout before the final fully connected layer\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "def ResNet12():\n",
    "    return ResNet(BasicBlock, [2, 1, 1, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a few helper functions to import the Kaggle dataset and format the training progress. Some are also taken from the `python-cifar` utility functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import zipfile\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "\n",
    "term_width = 50\n",
    "last_time = time.time()\n",
    "begin_time = last_time\n",
    "\n",
    "def progress_bar(current, total, msg=None):\n",
    "    bar_length = 60\n",
    "    progress = current / total\n",
    "\n",
    "    block = int(round(bar_length * progress))\n",
    "    # Use '>' as an arrow to indicate current progress position\n",
    "    # Note: The arrow is positioned at the end of the filled portion, except when progress is 0\n",
    "    arrow = \">\" if block < bar_length else \"\"\n",
    "    text = \"\\rProgress: [{0}{1}{2}] {3:.2f}% ({4}/{5}) {6}\".format(\n",
    "        \"=\" * (block - 1 if block > 0 else 0), arrow,\n",
    "        \"-\" * (bar_length - block), progress * 100, current, total,\n",
    "        msg if msg else \"\")\n",
    "    sys.stdout.write(text)\n",
    "    sys.stdout.flush()\n",
    "    if current == total:\n",
    "        sys.stdout.write('\\n')\n",
    "\n",
    "def format_time(seconds):\n",
    "    days = int(seconds / 3600/24)\n",
    "    seconds = seconds - days*3600*24\n",
    "    hours = int(seconds / 3600)\n",
    "    seconds = seconds - hours*3600\n",
    "    minutes = int(seconds / 60)\n",
    "    seconds = seconds - minutes*60\n",
    "    secondsf = int(seconds)\n",
    "    seconds = seconds - secondsf\n",
    "    millis = int(seconds*1000)\n",
    "\n",
    "    f = ''\n",
    "    i = 1\n",
    "    if days > 0:\n",
    "        f += str(days) + 'D'\n",
    "        i += 1\n",
    "    if hours > 0 and i <= 2:\n",
    "        f += str(hours) + 'h'\n",
    "        i += 1\n",
    "    if minutes > 0 and i <= 2:\n",
    "        f += str(minutes) + 'm'\n",
    "        i += 1\n",
    "    if secondsf > 0 and i <= 2:\n",
    "        f += str(secondsf) + 's'\n",
    "        i += 1\n",
    "    if millis > 0 and i <= 2:\n",
    "        f += str(millis) + 'ms'\n",
    "        i += 1\n",
    "    if f == '':\n",
    "        f = '0ms'\n",
    "    return f\n",
    "\n",
    "\n",
    "def unpickle(filename):\n",
    "    zf = zipfile.ZipFile(filename, \"r\")\n",
    "    data = pickle.loads(zf.open(\"cifar_test_nolabels.pkl\").read())\n",
    "    zf.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we instanciate our model and count the number of parameters. We also import the CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "==> Building model..\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "Count params:  4977226\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.init as init\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "combinedset = torch.utils.data.ConcatDataset([trainset, testset])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "combinedloader = torch.utils.data.DataLoader(\n",
    "    combinedset, batch_size=128, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Model\n",
    "print('==> Building model..')\n",
    "net = ResNet12()\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(net)\n",
    "count_params = count_parameters(net)\n",
    "print(\"Count params: \", count_params)\n",
    "assert count_params < 5000000, \"Parameters must be lower than 5 million\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "For training, we use `CrossEntropyLoss` to measure how the model is doing as it is a multi-class classification task. Next, we use the `Adam` optimizer to train the parameters. The learning rate will be updated using cosine annealing scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "# Loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Training Optimizer\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "# History\n",
    "train_loss_hist = []\n",
    "test_loss_hist = []\n",
    "\n",
    "# Training\n",
    "def train(epoch, dataloader):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        progress_bar(batch_idx+1, len(dataloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                     % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "    \n",
    "    # save the history\n",
    "    train_loss_hist.append(train_loss)\n",
    "\n",
    "\n",
    "def test(epoch, dataloader):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "            progress_bar(batch_idx+1, len(dataloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                          % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    # save the history\n",
    "    test_loss_hist.append(test_loss)\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/ckpt.pth')\n",
    "        best_acc = acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do 25 epochs of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "Progress: [===========================================================] 100.00% (391/391) Loss: 1.514 | Acc: 44.156% (22078/50000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 1.367 | Acc: 53.130% (5313/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 1\n",
      "Progress: [===========================================================] 100.00% (391/391) Loss: 1.101 | Acc: 60.414% (30207/50000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 1.006 | Acc: 64.490% (6449/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 2\n",
      "Progress: [===========================================================] 100.00% (391/391) Loss: 0.945 | Acc: 66.456% (33228/50000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.899 | Acc: 68.810% (6881/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 3\n",
      "Progress: [===========================================================] 100.00% (391/391) Loss: 0.854 | Acc: 69.702% (34851/50000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.841 | Acc: 70.990% (7099/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 4\n",
      "Progress: [===========================================================] 100.00% (391/391) Loss: 0.778 | Acc: 72.562% (36281/50000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.770 | Acc: 74.000% (7400/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 5\n",
      "Progress: [===========================================================] 100.00% (391/391) Loss: 0.692 | Acc: 75.612% (37806/50000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.696 | Acc: 77.130% (7713/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 6\n",
      "Progress: [===========================================================] 100.00% (391/391) Loss: 0.641 | Acc: 77.712% (38856/50000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.596 | Acc: 80.070% (8007/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 7\n",
      "Progress: [===========================================================] 100.00% (391/391) Loss: 0.594 | Acc: 79.318% (39659/50000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.571 | Acc: 81.060% (8106/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 8\n",
      "Progress: [===========================================================] 100.00% (391/391) Loss: 0.561 | Acc: 80.448% (40224/50000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.552 | Acc: 82.100% (8210/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 9\n",
      "Progress: [===========================================================] 100.00% (391/391) Loss: 0.529 | Acc: 81.730% (40865/50000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.507 | Acc: 83.310% (8331/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 10\n",
      "Progress: [===========================================================] 100.00% (391/391) Loss: 0.505 | Acc: 82.540% (41270/50000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.458 | Acc: 84.390% (8439/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 11\n",
      "Progress: [===========================================================] 100.00% (391/391) Loss: 0.484 | Acc: 83.382% (41691/50000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.476 | Acc: 84.130% (8413/10000)\n",
      "\n",
      "Epoch: 12\n",
      "Progress: [===========================================================] 100.00% (391/391) Loss: 0.460 | Acc: 84.206% (42103/50000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.423 | Acc: 85.610% (8561/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 13\n",
      "Progress: [===========================================================] 100.00% (391/391) Loss: 0.438 | Acc: 84.684% (42342/50000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.415 | Acc: 86.290% (8629/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 14\n",
      "Progress: [===========================================================] 100.00% (391/391) Loss: 0.426 | Acc: 85.082% (42541/50000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.417 | Acc: 86.190% (8619/10000)\n",
      "\n",
      "Epoch: 15\n",
      "Progress: [===========================================================] 100.00% (391/391) Loss: 0.408 | Acc: 85.840% (42920/50000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.400 | Acc: 86.860% (8686/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 16\n",
      "Progress: [===========================================================] 100.00% (391/391) Loss: 0.392 | Acc: 86.310% (43155/50000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.395 | Acc: 87.080% (8708/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 17\n",
      "Progress: [===========================================================] 100.00% (391/391) Loss: 0.382 | Acc: 86.758% (43379/50000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.363 | Acc: 87.970% (8797/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 18\n",
      "Progress: [===========================================================] 100.00% (391/391) Loss: 0.366 | Acc: 87.228% (43614/50000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.388 | Acc: 87.580% (8758/10000)\n",
      "\n",
      "Epoch: 19\n",
      "Progress: [===========================================================] 100.00% (391/391) Loss: 0.356 | Acc: 87.626% (43813/50000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.367 | Acc: 88.200% (8820/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 20\n",
      "Progress: [===========================================================] 100.00% (391/391) Loss: 0.345 | Acc: 88.022% (44011/50000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.364 | Acc: 88.110% (8811/10000)\n",
      "\n",
      "Epoch: 21\n",
      "Progress: [===========================================================] 100.00% (391/391) Loss: 0.337 | Acc: 88.410% (44205/50000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.350 | Acc: 88.700% (8870/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 22\n",
      "Progress: [===========================================================] 100.00% (391/391) Loss: 0.327 | Acc: 88.746% (44373/50000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.348 | Acc: 88.600% (8860/10000)\n",
      "\n",
      "Epoch: 23\n",
      "Progress: [===========================================================] 100.00% (391/391) Loss: 0.312 | Acc: 89.146% (44573/50000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.344 | Acc: 88.840% (8884/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 24\n",
      "Progress: [===========================================================] 100.00% (391/391) Loss: 0.311 | Acc: 89.274% (44637/50000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.333 | Acc: 89.130% (8913/10000)\n",
      "Saving..\n"
     ]
    }
   ],
   "source": [
    "# Do 25 epoch\n",
    "for epoch in range(start_epoch, start_epoch+25):\n",
    "    train(epoch, trainloader)\n",
    "    test(epoch, testloader)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe the loss over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(train_loss_hist, '-', linewidth=3, label='Train Error')\n",
    "plt.plot(test_loss_hist, '-', linewidth=3, label='Test Error')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the prediction performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[915,   8,  22,   8,   9,   1,   1,   2,  22,  12],\n",
       "       [  7, 938,   1,   0,   0,   0,   2,   1,   8,  43],\n",
       "       [ 26,   0, 876,  12,  22,  28,  27,   2,   4,   3],\n",
       "       [ 13,   0,  55, 752,  36,  91,  34,  12,   4,   3],\n",
       "       [  4,   0,  37,  11, 898,  13,  20,  17,   0,   0],\n",
       "       [  4,   0,  22,  90,  26, 838,   6,  14,   0,   0],\n",
       "       [ 12,   1,  32,  16,   7,   5, 922,   3,   2,   0],\n",
       "       [ 10,   0,  12,  15,  28,  34,   3, 896,   2,   0],\n",
       "       [ 33,   8,   3,   3,   0,   0,   0,   0, 941,  12],\n",
       "       [  8,  32,   1,   4,   3,   0,   1,   3,  11, 937]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (input_test,label_test) in enumerate(testloader):\n",
    "        input_test = input_test.to(device)\n",
    "        outputs = net(input_test.float())\n",
    "        _, predicted = outputs.max(1)\n",
    "        labels.append(predicted)\n",
    "\n",
    "# flatten the labels\n",
    "pred = np.array([])\n",
    "for batch in labels:\n",
    "    pred = np.append(pred, batch.tolist())\n",
    "\n",
    "# predict performance\n",
    "cf_matrix = confusion_matrix(testset.targets, pred)\n",
    "cf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the confusion matrix, it looks like all labels have around 90% accuracy score. We see that label 3 ('cat') has the lowest accuracy of 75.2%. Let's look at some wrong prediction examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print_testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 10))\n",
    "count = 0\n",
    "\n",
    "for i in range(0, len(pred)):\n",
    "    if print_testset.targets[i] != pred[i]:\n",
    "        # print the image\n",
    "        im = print_testset[i][0]\n",
    "        ax[count].imshow(im)\n",
    "        ax[count].set_title(\"Act:%s Pred:%s\" % (classes[print_testset.targets[i]], classes[int(pred[i])]))\n",
    "        count += 1\n",
    "\n",
    "    if count == 3:\n",
    "        break\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our best result, we trained the model using the combined dataset for 100 epochs with the RTX8000 GPU in NYU's HPC cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.319 | Acc: 88.993% (53396/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.220 | Acc: 92.520% (9252/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 1\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.299 | Acc: 89.637% (53782/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.203 | Acc: 92.860% (9286/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 2\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.286 | Acc: 90.023% (54014/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.146 | Acc: 95.160% (9516/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 3\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.276 | Acc: 90.288% (54173/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.119 | Acc: 96.070% (9607/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 4\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.269 | Acc: 90.657% (54394/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.103 | Acc: 96.660% (9666/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 5\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.261 | Acc: 90.820% (54492/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.088 | Acc: 97.100% (9710/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 6\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.249 | Acc: 91.208% (54725/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.077 | Acc: 97.560% (9756/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 7\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.243 | Acc: 91.317% (54790/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.063 | Acc: 98.210% (9821/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 8\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.236 | Acc: 91.718% (55031/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.059 | Acc: 98.340% (9834/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 9\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.232 | Acc: 91.933% (55160/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.048 | Acc: 98.670% (9867/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 10\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.221 | Acc: 92.240% (55344/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.043 | Acc: 98.950% (9895/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 11\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.215 | Acc: 92.513% (55508/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.037 | Acc: 99.100% (9910/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 12\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.212 | Acc: 92.527% (55516/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.037 | Acc: 98.990% (9899/10000)\n",
      "\n",
      "Epoch: 13\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.208 | Acc: 92.670% (55602/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.032 | Acc: 99.150% (9915/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 14\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.203 | Acc: 92.827% (55696/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.028 | Acc: 99.320% (9932/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 15\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.196 | Acc: 93.102% (55861/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.024 | Acc: 99.510% (9951/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 16\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.196 | Acc: 93.143% (55886/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.021 | Acc: 99.520% (9952/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 17\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.192 | Acc: 93.247% (55948/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.021 | Acc: 99.510% (9951/10000)\n",
      "\n",
      "Epoch: 18\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.188 | Acc: 93.428% (56057/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.018 | Acc: 99.670% (9967/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 19\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.180 | Acc: 93.622% (56173/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.017 | Acc: 99.700% (9970/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 20\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.178 | Acc: 93.777% (56266/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.019 | Acc: 99.610% (9961/10000)\n",
      "\n",
      "Epoch: 21\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.176 | Acc: 93.785% (56271/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.017 | Acc: 99.660% (9966/10000)\n",
      "\n",
      "Epoch: 22\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.172 | Acc: 93.920% (56352/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.017 | Acc: 99.680% (9968/10000)\n",
      "\n",
      "Epoch: 23\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.168 | Acc: 93.943% (56366/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.014 | Acc: 99.780% (9978/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 24\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.163 | Acc: 94.345% (56607/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.012 | Acc: 99.780% (9978/10000)\n",
      "\n",
      "Epoch: 25\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.160 | Acc: 94.337% (56602/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.012 | Acc: 99.810% (9981/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 26\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.158 | Acc: 94.458% (56675/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.012 | Acc: 99.750% (9975/10000)\n",
      "\n",
      "Epoch: 27\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.156 | Acc: 94.428% (56657/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.009 | Acc: 99.910% (9991/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 28\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.155 | Acc: 94.518% (56711/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.010 | Acc: 99.900% (9990/10000)\n",
      "\n",
      "Epoch: 29\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.153 | Acc: 94.635% (56781/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.009 | Acc: 99.840% (9984/10000)\n",
      "\n",
      "Epoch: 30\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.146 | Acc: 94.848% (56909/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.009 | Acc: 99.860% (9986/10000)\n",
      "\n",
      "Epoch: 31\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.148 | Acc: 94.700% (56820/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.008 | Acc: 99.890% (9989/10000)\n",
      "\n",
      "Epoch: 32\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.141 | Acc: 95.072% (57043/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.008 | Acc: 99.920% (9992/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 33\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.142 | Acc: 94.960% (56976/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.008 | Acc: 99.850% (9985/10000)\n",
      "\n",
      "Epoch: 34\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.139 | Acc: 95.152% (57091/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.007 | Acc: 99.920% (9992/10000)\n",
      "\n",
      "Epoch: 35\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.133 | Acc: 95.317% (57190/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.006 | Acc: 99.880% (9988/10000)\n",
      "\n",
      "Epoch: 36\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.136 | Acc: 95.255% (57153/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.008 | Acc: 99.850% (9985/10000)\n",
      "\n",
      "Epoch: 37\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.133 | Acc: 95.235% (57141/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.005 | Acc: 99.950% (9995/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 38\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.132 | Acc: 95.227% (57136/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.007 | Acc: 99.850% (9985/10000)\n",
      "\n",
      "Epoch: 39\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.125 | Acc: 95.585% (57351/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.006 | Acc: 99.920% (9992/10000)\n",
      "\n",
      "Epoch: 40\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.126 | Acc: 95.545% (57327/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.006 | Acc: 99.900% (9990/10000)\n",
      "\n",
      "Epoch: 41\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.123 | Acc: 95.577% (57346/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.005 | Acc: 99.970% (9997/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 42\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.119 | Acc: 95.883% (57530/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.004 | Acc: 99.980% (9998/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 43\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.122 | Acc: 95.615% (57369/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.005 | Acc: 99.940% (9994/10000)\n",
      "\n",
      "Epoch: 44\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.116 | Acc: 95.850% (57510/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.004 | Acc: 99.950% (9995/10000)\n",
      "\n",
      "Epoch: 45\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.111 | Acc: 96.098% (57659/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.004 | Acc: 99.960% (9996/10000)\n",
      "\n",
      "Epoch: 46\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.111 | Acc: 96.083% (57650/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.005 | Acc: 99.940% (9994/10000)\n",
      "\n",
      "Epoch: 47\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.113 | Acc: 95.967% (57580/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.004 | Acc: 99.950% (9995/10000)\n",
      "\n",
      "Epoch: 48\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.111 | Acc: 96.020% (57612/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.005 | Acc: 99.940% (9994/10000)\n",
      "\n",
      "Epoch: 49\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.108 | Acc: 96.175% (57705/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.004 | Acc: 99.930% (9993/10000)\n",
      "\n",
      "Epoch: 50\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.107 | Acc: 96.263% (57758/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.003 | Acc: 99.970% (9997/10000)\n",
      "\n",
      "Epoch: 51\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.104 | Acc: 96.307% (57784/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.004 | Acc: 99.970% (9997/10000)\n",
      "\n",
      "Epoch: 52\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.104 | Acc: 96.302% (57781/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.003 | Acc: 100.000% (10000/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 53\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.102 | Acc: 96.378% (57827/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.003 | Acc: 99.960% (9996/10000)\n",
      "\n",
      "Epoch: 54\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.101 | Acc: 96.390% (57834/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.002 | Acc: 99.980% (9998/10000)\n",
      "\n",
      "Epoch: 55\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.098 | Acc: 96.528% (57917/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.003 | Acc: 99.980% (9998/10000)\n",
      "\n",
      "Epoch: 56\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.096 | Acc: 96.602% (57961/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.002 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 57\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.098 | Acc: 96.530% (57918/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.003 | Acc: 99.960% (9996/10000)\n",
      "\n",
      "Epoch: 58\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.093 | Acc: 96.737% (58042/60000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.002 | Acc: 99.980% (9998/10000)\n",
      "\n",
      "Epoch: 59\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.093 | Acc: 96.728% (58037/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.002 | Acc: 99.990% (9999/10000)\n",
      "\n",
      "Epoch: 60\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.092 | Acc: 96.783% (58070/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.002 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 61\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.089 | Acc: 96.823% (58094/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.002 | Acc: 99.990% (9999/10000)\n",
      "\n",
      "Epoch: 62\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.091 | Acc: 96.683% (58010/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.002 | Acc: 99.980% (9998/10000)\n",
      "\n",
      "Epoch: 63\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.087 | Acc: 96.943% (58166/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.003 | Acc: 99.970% (9997/10000)\n",
      "\n",
      "Epoch: 64\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.084 | Acc: 97.018% (58211/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.002 | Acc: 99.970% (9997/10000)\n",
      "\n",
      "Epoch: 65\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.087 | Acc: 96.887% (58132/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.002 | Acc: 99.980% (9998/10000)\n",
      "\n",
      "Epoch: 66\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.084 | Acc: 96.990% (58194/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.002 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 67\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.084 | Acc: 96.975% (58185/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.002 | Acc: 99.990% (9999/10000)\n",
      "\n",
      "Epoch: 68\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.081 | Acc: 97.183% (58310/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 69\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.077 | Acc: 97.323% (58394/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.002 | Acc: 99.990% (9999/10000)\n",
      "\n",
      "Epoch: 70\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.084 | Acc: 97.110% (58266/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 71\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.076 | Acc: 97.352% (58411/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.002 | Acc: 99.980% (9998/10000)\n",
      "\n",
      "Epoch: 72\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.076 | Acc: 97.347% (58408/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 73\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.076 | Acc: 97.323% (58394/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 99.990% (9999/10000)\n",
      "\n",
      "Epoch: 74\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.073 | Acc: 97.392% (58435/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 99.990% (9999/10000)\n",
      "\n",
      "Epoch: 75\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.076 | Acc: 97.342% (58405/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 99.990% (9999/10000)\n",
      "\n",
      "Epoch: 76\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.071 | Acc: 97.540% (58524/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 77\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.069 | Acc: 97.542% (58525/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 78\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.068 | Acc: 97.558% (58535/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 99.980% (9998/10000)\n",
      "\n",
      "Epoch: 79\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.069 | Acc: 97.657% (58594/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 80\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.070 | Acc: 97.447% (58468/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 99.980% (9998/10000)\n",
      "\n",
      "Epoch: 81\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.069 | Acc: 97.533% (58520/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 99.990% (9999/10000)\n",
      "\n",
      "Epoch: 82\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.065 | Acc: 97.675% (58605/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 99.990% (9999/10000)\n",
      "\n",
      "Epoch: 83\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.064 | Acc: 97.710% (58626/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 84\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.062 | Acc: 97.775% (58665/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 99.990% (9999/10000)\n",
      "\n",
      "Epoch: 85\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.062 | Acc: 97.843% (58706/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 99.980% (9998/10000)\n",
      "\n",
      "Epoch: 86\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.063 | Acc: 97.758% (58655/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 87\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.059 | Acc: 97.947% (58768/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 88\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.061 | Acc: 97.812% (58687/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 89\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.059 | Acc: 97.873% (58724/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 90\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.060 | Acc: 97.888% (58733/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 91\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.058 | Acc: 97.968% (58781/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 92\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.059 | Acc: 97.987% (58792/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 93\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.055 | Acc: 98.048% (58829/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 99.990% (9999/10000)\n",
      "\n",
      "Epoch: 94\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.057 | Acc: 97.952% (58771/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 95\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.054 | Acc: 98.105% (58863/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 96\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.055 | Acc: 98.070% (58842/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.001 | Acc: 99.990% (9999/10000)\n",
      "\n",
      "Epoch: 97\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.054 | Acc: 98.117% (58870/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 98\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.050 | Acc: 98.220% (58932/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n",
      "\n",
      "Epoch: 99\n",
      "Progress: [===========================================================] 100.00% (469/469) Loss: 0.050 | Acc: 98.228% (58937/60000)\n",
      "Progress: [===========================================================] 100.00% (100/100) Loss: 0.000 | Acc: 100.000% (10000/10000)\n"
     ]
    }
   ],
   "source": [
    "# Do 100 epoch\n",
    "for epoch in range(start_epoch, start_epoch+100):\n",
    "    train(epoch, combinedloader)\n",
    "    test(epoch, testloader)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "For the Kaggle data prediction, we will import the trained model and start predicting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (linear): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.init as init\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Model\n",
    "print('==> Building model..')\n",
    "net = ResNet12()\n",
    "net = net.to(device)\n",
    "net = torch.nn.DataParallel(net)\n",
    "if device == 'cuda':\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "# load state\n",
    "saved_model = torch.load('./checkpoint/ckpt.pth', map_location=torch.device(device))\n",
    "net.load_state_dict(saved_model['net'])\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the raw data and predict in batches of a thousand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 done\n",
      "Batch 2 done\n",
      "Batch 3 done\n",
      "Batch 4 done\n",
      "Batch 5 done\n",
      "Batch 6 done\n",
      "Batch 7 done\n",
      "Batch 8 done\n",
      "Batch 9 done\n",
      "Batch 10 done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "cifar_test_nolabels = unpickle(\"../data/cifar_test_nolabels.pkl.zip\")\n",
    "competition_data = cifar_test_nolabels[b'data']\n",
    "y_id = cifar_test_nolabels[b'ids']\n",
    "\n",
    "competitionset = []\n",
    "for d in competition_data:\n",
    "    # transpose flatten CIFAR image to RGB\n",
    "    d = d.reshape(3, 32, 32).transpose(1,2,0)\n",
    "    im = Image.fromarray(d, mode='RGB')\n",
    "    im = transform_test(im)\n",
    "    competitionset.append(im)\n",
    "\n",
    "competitionloader = torch.utils.data.DataLoader(\n",
    "    competitionset, batch_size=1000, shuffle=False)\n",
    "\n",
    "labels = []\n",
    "\n",
    "def competition_test():\n",
    "    net.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, input_test in enumerate(competitionloader):\n",
    "            input_test = input_test.to(device)\n",
    "            outputs = net(input_test.float())\n",
    "            _, predicted = outputs.max(1)\n",
    "            labels.append(predicted)\n",
    "            print(\"Batch %d done\" % (batch_idx + 1))\n",
    "\n",
    "            \n",
    "competition_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we write the prediction labels into a .csv file for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# flatten the labels\n",
    "pred = np.array([])\n",
    "for batch in labels:\n",
    "    pred = np.append(pred, batch.tolist())\n",
    "\n",
    "\n",
    "competition_data_ids = unpickle(\"../data/cifar_test_nolabels.pkl.zip\")[b'ids']\n",
    "    \n",
    "# create dataframe to save prediction\n",
    "df = pd.DataFrame()\n",
    "df['ID'] = competition_data_ids\n",
    "df['Label'] = pred\n",
    "df['Label'] = df['Label'].astype(int)\n",
    "\n",
    "df.to_csv('out.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
